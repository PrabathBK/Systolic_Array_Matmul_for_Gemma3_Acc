# Systolic Array Matrix Multiplication IPs for Gemma LLM Accelerator

This repository contains multiple **systolic array accelerator IPs** designed to accelerate the **Gemma LLM inference engine** on FPGA/SoC platforms. It includes parameterized RTL implementations, tiling extensions, host test software, and integration with the **VEGA RISC-V processor**.

## ğŸš€ Features

- **High-throughput INT8 systolic array** accelerators (16Ã—16, 32Ã—32)
- **Tiling support**: large matrix multiplication using smaller arrays (e.g., 32Ã—32 via 16Ã—16 tiles)
- **Scalable systolic arrays**: INT4/FP16 variants, parametrized dimensions
- **AXI-Lite + AXI4 interfaces** for CPU-controlled SoC integration
- **Full Vivado testbenches** for simulation and verification
- **Integration with VEGA SoC** for real benchmarks
- Includes **waveform captures, benchmark results, and block diagrams** for documentation

## ğŸ“‚ Repository Structure

```
Systolic_Array_Matmul_for_Gemma3_Acc/
â”œâ”€â”€ Accelerator_IP/
â”‚   â”œâ”€â”€ Gemma_Accelerator_IP/
â”‚   â”‚   â”œâ”€â”€ INT8_16x16/                    # 16x16 INT8 systolic array IP
â”‚   â”‚   â”œâ”€â”€ INT8_32x32/                    # 32x32 INT8 systolic array IP
â”‚   â”‚   â””â”€â”€ Tiling/                        # Tiling implementation (32x32 using 16x16)
â”‚   â””â”€â”€ Systolic_array_IP/
â”‚       â”œâ”€â”€ Scalable_sytolic_matmul_axi/
â”‚       â”‚   â”œâ”€â”€ INT4_INT4/
â”‚       â”‚   â”‚   â”œâ”€â”€ Final_DMA_v2/          # DMA-enabled version
â”‚       â”‚   â”‚   â””â”€â”€ Final_v1/              # Basic version
â”‚       â”‚   â””â”€â”€ f16_INT4/                  # FP16Ã—INT4 implementation
â”‚       â”œâ”€â”€ not_scalable_systolic_matmul/  # Initial fixed-size design
â”‚       â””â”€â”€ scalable_systolic_matmul/      # Parameterized systolic arrays
â”œâ”€â”€ Application/
â”‚   â””â”€â”€ INT8_16x16/
â”‚       â”œâ”€â”€ benchmark.c                    # Performance benchmarking code
â”‚       â”œâ”€â”€ host.c                         # Host-side control software
â”‚       â”œâ”€â”€ main.c                         # Main application entry point
â”‚       â””â”€â”€ matmul_offload.c              # Matrix multiplication offload functions
â”œâ”€â”€ .gitattributes
â””â”€â”€ README.md
```

## ğŸ–¼ï¸ Architecture Overview

### Systolic Array Block Diagram
![systolic array architecture diagram](https://github.com/PrabathBK/Systolic_Array_Matmul_for_Gemma3_Acc/blob/main/Results/sys_block.png)


The systolic array consists of a grid of Processing Elements (PEs) that perform matrix multiplication in a pipelined fashion. Data flows through the array in a wave-like pattern, maximizing computational throughput.

### Tiling Architecture (32Ã—32 via 16Ã—16 tiles)
![Tilling architecture diagram](https://github.com/PrabathBK/Systolic_Array_Matmul_for_Gemma3_Acc/blob/main/Results/Acc_IP.png)

The tiling implementation allows larger matrix multiplications by decomposing them into smaller sub-matrices that fit within the 16Ã—16 systolic array, then combining the results.

## ğŸ§© Key RTL Modules

### Gemma Accelerator IP
- **`gemma_accelerator.v`** - Top-level module with AXI-Lite control registers and AXI4 memory interfaces
- **`systolic_array_16x16.v`** - Configurable 16Ã—16 systolic array grid
- **`pe_int8.v`** - Processing element: INT8Ã—INT8 multiply with 32-bit accumulation
- **`accelerator_buffer.v`** - Input/output buffers for A, B matrices and result staging

### Systolic Array IP Variants
- **Scalable Implementation**: Parameterized systolic arrays supporting various dimensions
- **INT4 Support**: Optimized for quantized neural network inference
- **FP16Ã—INT4**: Mixed-precision multiplication for enhanced accuracy
- **DMA Integration**: Direct memory access for improved data transfer efficiency

## ğŸ“Š Benchmarks & Results

### Simulation and Implementation Results

#### INT8 16Ã—16 IP on VEGA Processor SoC
- âœ… **Simulation verified** (waveform screenshots below)
![IP Wave - Data flow](https://github.com/PrabathBK/Systolic_Array_Matmul_for_Gemma3_Acc/blob/main/Results/IP1.png)
![IP Wave - Results](https://github.com/PrabathBK/Systolic_Array_Matmul_for_Gemma3_Acc/blob/main/Results/IP2.png)

- âœ… **Hardware implementation successful - Benchmark**
![Systolic SOC Benchmark](https://github.com/PrabathBK/Systolic_Array_Matmul_for_Gemma3_Acc/blob/main/Results/systolic_soc_implementation.png)

- âœ… **Hardware implementation successful - Offload**
![Systolic SOC offload](https://github.com/PrabathBK/Systolic_Array_Matmul_for_Gemma3_Acc/blob/main/Results/offload_result.jpeg)


#### Tiling IP (32Ã—32 using 16Ã—16 systolic array) on SoC
- âœ… **Implementation Results**
![Systolic SOC Benchmark](https://github.com/PrabathBK/Systolic_Array_Matmul_for_Gemma3_Acc/blob/main/Results/Tiling_log.png)



#### Integration with VEGA Processor

1. **Load data into memory** (A, B matrices)
2. **Configure accelerator via AXI-Lite**:
   - Write base addresses (A, B, C matrices)
   - Set matrix dimensions
   - Set start bit
3. **Wait for completion** (done flag or interrupt)
4. **Read results from memory** (C matrix)


## ğŸ”§ Configuration Options

### Compile-time Parameters
- `ARRAY_SIZE`: Systolic array dimensions (default: 16)
- `DATA_WIDTH`: Input data width (8 for INT8, 4 for INT4)
- `ACCUMULATOR_WIDTH`: Output accumulator width (default: 32)
- `BUFFER_DEPTH`: Input/output buffer depth

### Runtime Configuration
- Matrix dimensions (up to maximum supported by array size)
- Memory addresses for input/output matrices
- Interrupt enable/disable
- Debug mode enable/disable

## ğŸš€ Performance Optimization Tips

1. **Memory Layout**: Use contiguous memory allocation for better cache performance
2. **Data Alignment**: Align matrices to cache line boundaries
3. **Tiling Strategy**: Choose tile sizes that maximize array utilization
4. **Pipeline Optimization**: Overlap data loading with computation when possible


**Note**: This accelerator is designed specifically for the Gemma LLM inference pipeline and may require modifications for other neural network architectures.
